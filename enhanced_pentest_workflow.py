#!/usr/bin/env python3
"""
Integration example: Using AI vulnerability analysis in penetration testing workflow
Shows how to integrate SQL injection, XSS, and logical flaw analysis into main crawler
"""

import asyncio
import json
import sys
from pathlib import Path
from urllib.parse import urlparse, parse_qs

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from intelligent_terminal_ai.core.ai_analyzer import AIAnalyzer
from intelligent_terminal_ai.utils.config import config

class EnhancedPenetrationTester:
    """Enhanced penetration tester with AI-powered vulnerability analysis"""
    
    def __init__(self):
        """Initialize with AI analyzer"""
        # Get AI configuration
        provider = config.get("ai", "provider", "groq")
        provider_config = config.get("ai", provider, {})
        
        if provider == "groq":
            model = f"groq-{provider_config.get('model', 'llama-3.1-8b-instant')}"
            api_key = provider_config.get("api_key")
        else:
            model = "groq-llama-3.1-8b-instant"
            api_key = "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"
        
        self.ai_analyzer = AIAnalyzer(model=model, api_key=api_key)
        self.vulnerabilities_found = []
        
        print(f"🤖 AI Analyzer initialized with {provider.upper()}")
        print(f"🧠 Model: {model}")
        print()
    
    async def analyze_url_for_vulnerabilities(self, url: str, form_data: dict = None, page_html: str = ""):
        """Comprehensive vulnerability analysis for a URL"""
        
        print(f"🔍 ANALYZING URL: {url}")
        print("=" * 60)
        
        parsed_url = urlparse(url)
        query_params = parse_qs(parsed_url.query)
        
        vulnerability_report = {
            "url": url,
            "sql_injection": [],
            "xss_vulnerabilities": [],
            "logical_flaws": [],
            "total_vulnerabilities": 0
        }
        
        # 1. SQL Injection Analysis
        print("🔒 Phase 1: SQL Injection Analysis")
        print("-" * 30)
        
        for param_name, param_values in query_params.items():
            if param_values:  # Skip empty parameters
                print(f"   Testing parameter: {param_name}")
                
                sqli_result = await self.ai_analyzer.analyze_sqli_vulnerability(
                    url=url,
                    parameter_name=param_name,
                    http_method="GET",
                    technology_stack="PHP, Apache, MySQL",  # This would be detected in real scenario
                    html_snippet=f'<input name="{param_name}" value="{param_values[0]}">'
                )
                
                if sqli_result.get("success", False):
                    payloads = sqli_result.get("sqli_analysis", [])
                    if payloads:
                        print(f"   ✅ Found {len(payloads)} SQL injection payloads for {param_name}")
                        vulnerability_report["sql_injection"].extend(payloads)
                        
                        # Show highest confidence payload
                        best_payload = max(payloads, key=lambda x: x.get('confidence_score', 0))
                        print(f"      🎯 Best payload: {best_payload.get('payload', 'None')}")
                        print(f"      🎯 Confidence: {best_payload.get('confidence_score', 0)}/10")
                    else:
                        print(f"   ⚪ No SQL injection vulnerabilities found for {param_name}")
                else:
                    print(f"   ❌ SQL injection analysis failed for {param_name}")
        
        # 2. XSS Analysis
        print("\n🔓 Phase 2: XSS Analysis")
        print("-" * 30)
        
        if page_html or query_params:
            # Use provided HTML or create mock HTML for demo
            test_html = page_html or f"""
<!DOCTYPE html>
<html>
<head><title>Test Page</title></head>
<body>
    <form method="GET" action="{parsed_url.path}">
    {''.join(f'<input name="{name}" value="{values[0] if values else ""}">' for name, values in query_params.items())}
    </form>
    <div class="results">
    {''.join(f'<p>Parameter {name}: <strong>{values[0] if values else ""}</strong></p>' for name, values in query_params.items())}
    </div>
</body>
</html>
            """
            
            for param_name in query_params.keys():
                print(f"   Testing XSS for parameter: {param_name}")
                
                xss_result = await self.ai_analyzer.analyze_xss_vulnerability(
                    url=url,
                    parameter_name=param_name,
                    technology_hints="PHP, JavaScript, jQuery",
                    full_page_html=test_html
                )
                
                if xss_result.get("success", False):
                    xss_payloads = xss_result.get("xss_analysis", [])
                    if xss_payloads:
                        print(f"   ✅ Found {len(xss_payloads)} XSS payloads for {param_name}")
                        vulnerability_report["xss_vulnerabilities"].extend(xss_payloads)
                        
                        # Show highest confidence payload
                        best_xss = max(xss_payloads, key=lambda x: x.get('confidence_score', 0))
                        print(f"      🎯 Best payload: {best_xss.get('payload', 'None')}")
                        print(f"      🎯 Technique: {best_xss.get('bypass_technique', 'Unknown')}")
                        print(f"      🎯 Confidence: {best_xss.get('confidence_score', 0)}/10")
                    else:
                        print(f"   ⚪ No XSS vulnerabilities found for {param_name}")
                else:
                    print(f"   ❌ XSS analysis failed for {param_name}")
        
        # 3. Logical Flaw Analysis (IDOR/Path Traversal)
        print("\n🔑 Phase 3: Logical Flaw Analysis")
        print("-" * 30)
        
        # Mock discovered directories (in real scenario, these would be discovered during crawling)
        mock_directories = ["/admin", "/config", "/backup", "/includes", "/uploads", "/logs"]
        
        logical_result = await self.ai_analyzer.analyze_logical_flaws(
            full_url_with_params=url,
            discovered_directories=mock_directories,
            server_software="Apache 2.4"
        )
        
        if logical_result.get("success", False):
            logical_flaws = logical_result.get("logical_flaw_analysis", [])
            if logical_flaws:
                print(f"   ✅ Found {len(logical_flaws)} potential logical vulnerabilities")
                vulnerability_report["logical_flaws"] = logical_flaws
                
                for flaw in logical_flaws:
                    print(f"      🎯 {flaw.get('vulnerability_type', 'Unknown')}: {flaw.get('parameter_to_test', 'Unknown')}")
                    print(f"      🎯 Confidence: {flaw.get('confidence_score', 0)}/10")
            else:
                print(f"   ⚪ No logical flaws identified")
        else:
            print(f"   ❌ Logical flaw analysis failed")
        
        # Calculate total vulnerabilities
        vulnerability_report["total_vulnerabilities"] = (
            len(vulnerability_report["sql_injection"]) +
            len(vulnerability_report["xss_vulnerabilities"]) +
            len(vulnerability_report["logical_flaws"])
        )
        
        return vulnerability_report
    
    async def generate_penetration_test_report(self, target_urls: list):
        """Generate comprehensive penetration test report for multiple URLs"""
        
        print("🛡️ COMPREHENSIVE PENETRATION TEST REPORT")
        print("🤖 AI-Powered Vulnerability Analysis")
        print("=" * 70)
        
        all_vulnerabilities = []
        
        for i, url in enumerate(target_urls, 1):
            print(f"\n📍 TARGET {i}/{len(target_urls)}: {url}")
            print("=" * 50)
            
            vuln_report = await self.analyze_url_for_vulnerabilities(url)
            all_vulnerabilities.append(vuln_report)
            
            print(f"\n📊 SUMMARY FOR {url}:")
            print(f"   🔒 SQL Injection Vulnerabilities: {len(vuln_report['sql_injection'])}")
            print(f"   🔓 XSS Vulnerabilities: {len(vuln_report['xss_vulnerabilities'])}")
            print(f"   🔑 Logical Flaws: {len(vuln_report['logical_flaws'])}")
            print(f"   📈 Total Vulnerabilities: {vuln_report['total_vulnerabilities']}")
            
            if vuln_report['total_vulnerabilities'] > 0:
                print("   🚨 VULNERABLE - Requires immediate attention!")
            else:
                print("   ✅ No vulnerabilities detected")
        
        # Overall summary
        print("\n" + "=" * 70)
        print("📋 OVERALL PENETRATION TEST SUMMARY")
        print("=" * 70)
        
        total_sqli = sum(len(v['sql_injection']) for v in all_vulnerabilities)
        total_xss = sum(len(v['xss_vulnerabilities']) for v in all_vulnerabilities)
        total_logical = sum(len(v['logical_flaws']) for v in all_vulnerabilities)
        total_all = sum(v['total_vulnerabilities'] for v in all_vulnerabilities)
        
        print(f"🎯 Targets Tested: {len(target_urls)}")
        print(f"🔒 SQL Injection Vulnerabilities: {total_sqli}")
        print(f"🔓 XSS Vulnerabilities: {total_xss}")
        print(f"🔑 Logical Flaws: {total_logical}")
        print(f"📊 Total Vulnerabilities Found: {total_all}")
        
        # Risk assessment
        if total_all == 0:
            print("\n✅ EXCELLENT: No vulnerabilities detected across all targets")
        elif total_all <= 5:
            print("\n⚠️  LOW RISK: Few vulnerabilities found - review and patch")
        elif total_all <= 15:
            print("\n🚨 MEDIUM RISK: Multiple vulnerabilities found - immediate action required")
        else:
            print("\n🚨 HIGH RISK: Critical vulnerabilities found - urgent patching required")
        
        print(f"\n🤖 Analysis powered by {self.ai_analyzer.provider.upper()} AI")
        print("🔥 Ready for production security testing!")
        
        return all_vulnerabilities

async def main():
    """Demonstrate enhanced penetration testing with AI vulnerability analysis"""
    
    # Initialize enhanced penetration tester
    tester = EnhancedPenetrationTester()
    
    # Test URLs (mix of potentially vulnerable and safe URLs)
    test_targets = [
        "http://testphp.vulnweb.com/artists.php?artist=1",
        "http://testphp.vulnweb.com/search.php?searchFor=test",
        "http://testphp.vulnweb.com/userinfo.php?uname=admin",
        "https://example.com/download.php?file=report.pdf&user_id=123",
        "https://api.company.com/v1/users/456/profile?include_sensitive=true"
    ]
    
    # Generate comprehensive penetration test report  
    vulnerability_reports = await tester.generate_penetration_test_report(test_targets)
    
    # Save detailed report to JSON file
    report_file = "ai_vulnerability_analysis_report.json"
    with open(report_file, 'w') as f:
        json.dump(vulnerability_reports, f, indent=2)
    
    print(f"\n💾 Detailed report saved to: {report_file}")
    print("🎉 Enhanced penetration testing workflow complete!")

if __name__ == "__main__":
    asyncio.run(main())
